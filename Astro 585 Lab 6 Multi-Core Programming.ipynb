{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Astro 585 Spring 2014<br>\n",
      "Homework 6:  Parallel Computing:  Multi-Core Workstations"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Q1.  First, we'll parallelize some simple code from a previous exercise.  I'll walk you though the syntax in Julia and highlight some potential mistakes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, check how many processors your computer has.  On linux, you can do this by running /cat/cpuinfo from the command line and seeing how many processors are listed.\n",
      "If your machine only has one, then ssh to another computer with Julia installed for the parallel parts.  \n",
      "Next, check how many processor Julia is currently using."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nprocs()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When using the REPL interface, you can tell Julia to use multiple cores on a single workstation by starting it like \"julia -p 4\".\n",
      "When using IJulia, it's easier to tell it to add processors from within the notebook with the addprocs(N) command.\n",
      "Using addprocs(N) to tell Julia to use as many processors as your workstation has.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#addprocs(4)\n",
      "#for MacBook only add 2 cores\n",
      "addprocs(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "2-element Array{Any,1}:\n",
        " 2\n",
        " 3"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, check how many processor and how many \"workers\" are active."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 2\n",
        "myid()= 1\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1a.  What's the differences between nprocs() and nworkers()?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can instruct Julia to start a calculation on another node using @spawn or @spawnat.  \n",
      "Since the whole point is you want multiple processors working at once, you don't want to have ot wait until that function finished.\n",
      "Therefore, these macros return a RemoteRef data type, rather than the return value.  You can retreive the returned value using fetch."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ref = @spawn 1+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "RemoteRef(3,1,4)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fetch(ref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define our beloved normal pdf function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normal_pdf(x) = exp(-0.5*x.*x)./sqrt(2.*pi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "normal_pdf (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's write a loop-based integrate function like from the previous lab."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate \\int_a^b dx func(x) using n function evaluations\n",
      "# Approximates integral as uniformly spaced rectangles\n",
      "# Avoids evaluating func at a or b, in case of singularities\n",
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "int_normal_pdf (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's write a function to perform a few tests that our function is accurate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Base.Test\n",
      "function test_int_normal_pdf(func::Function; n::Integer = 1000000, eps::Real = 1.0e-6)\n",
      "  limits = 1:5\n",
      "  for limit in limits\n",
      "    @test_approx_eq_eps func(-limit,limit) erf(limit/sqrt(2.0)) eps\n",
      "  end\n",
      "end\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "int_normal_pdf not defined\nat In[3]:8",
       "output_type": "pyerr",
       "traceback": [
        "int_normal_pdf not defined\nat In[3]:8"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's parallelize that loop using the @parallel macro and test the function for accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  @parallel for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nat In[12]:11",
       "output_type": "pyerr",
       "traceback": [
        "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nat In[12]:11",
        " in error at error.jl:22",
        " in test_approx_eq at test.jl:68",
        " in test_int_normal_pdf at In[8]:5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "exception on 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        ": ERROR: normal_pdf not defined\n",
        " in anonymous at no file:6\n",
        " in anonymous at multi.jl:1278\n",
        " in anonymous at multi.jl:827\n",
        " in run_work_thunk at multi.jl:575\n",
        " in run_work_thunk at multi.jl:584\n",
        " in anonymous at task.jl:88\n",
        "exception on 3: ERROR: normal_pdf not defined\n",
        " in anonymous at no file:6\n",
        " in anonymous at multi.jl:1278\n",
        " in anonymous at multi.jl:827\n",
        " in run_work_thunk at multi.jl:575\n",
        " in run_work_thunk at multi.jl:584\n",
        " in anonymous at task.jl:88\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1b.  Notice that we get messages like normal_pdf not defined.  Why is that?  \n",
      "\n",
      "We've defined functions on only the first processor.  We need to make sure they're also definied on any other processors that we want to use the functions.  The easiest way to do that is with the @everywhere macro.  You can either stick it in front of each function (in your notebook) or save the functions to a file and load them with @everywhere include(\"file.jl\").  \n",
      "Let's redefine the above functions, but now forcing them to be declared on each processor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere normal_pdf(x) = exp(-0.5*x.*x)./sqrt(2.*pi)\n",
      "@everywhere using Base.Test\n",
      "\n",
      "@everywhere function test_int_normal_pdf(func::Function; n::Integer = 1000000, eps::Real = 1.0e-6)\n",
      "  limits = 1:5\n",
      "  for limit in limits\n",
      "    @test_approx_eq_eps func(-limit,limit) erf(limit/sqrt(2.0)) eps\n",
      "  end\n",
      "end\n",
      "\n",
      "@everywhere function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  @parallel for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nat In[13]:21",
       "output_type": "pyerr",
       "traceback": [
        "assertion failed: |:(func(-(limit),limit)) - :(erf(/(limit,sqrt(2.0))))| <= 1.0e-6\n  :(func(-(limit),limit)) = 0.0\n  :(erf(/(limit,sqrt(2.0)))) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nat In[13]:21",
        " in error at error.jl:22",
        " in test_approx_eq at test.jl:68",
        " in test_int_normal_pdf at In[13]:7"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1c.  Now, we've eliminated some of the error messages, but our test still fails.  And it can fail badly.  Why is that?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This type of operation is so common, that Julia provides a special syntax that makes this kind of loop easy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = @parallel (+) for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "034522566 seconds (225012 bytes allocated)\n",
        "elapsed time: 0.018724591 seconds (143744 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.6826896908849515"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here Julia is taking the last line of the for loop as the value to be \"reduced\" by the \"+\" operator and the result is stored in integral.  Note that the loop is no longer executed in order, since different processors are executing different parts of the loop."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, let's try performing the same calculation using parallel map function (pmap)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real,b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  dx = (b-a)/n\n",
      "  x = (a+0.5*dx):dx:(b-0.5*dx)\n",
      "  integral = sum(pmap(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0)\n",
      "@time  int_normal_pdf(-1.0,1.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".05155077 seconds (5334682844 bytes allocated)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 102"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".759791841 seconds (5325966868 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.6826894921371667"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yikes, that's crazy slow.  You may even want to restart the kernel.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll make use of distributed arrays to demonstrate how to handle more complex parallelization tasks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = sum(map(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".57652144 seconds (106005152 bytes allocated)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".941119278 seconds (69811368 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.682709365328419"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = sum(pmap(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)\n",
      "@time  int_normal_pdf(-1.0,1.0,10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".568671386 seconds (246031376 bytes allocated)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".448597159 seconds (244721496 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "1.359253198817778"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While we succeeded in using distributed array, the performance wasn't very good.  \n",
      "Next, we'll implement a more efficient parallelization using distribute arrays.  \n",
      "For this, you'll need to look up several functions in line 3 below and consider them piece by piece.  \n",
      "First, create a distributed array with dzeros, dones, drand or drandn.  \n",
      "Then, look at which processors are storing data for that array with procs().\n",
      "Then, check how much of the array is stored on the processor running your notebook using localpart() or myindexes()\n",
      "Then, use @spawnat and localpart() to have a processor operate only on the portion of the distributed array that it has in its own memory.\n",
      "Then use fetch with map to retreive the results from each processor working on it's own portion of the distributed array.\n",
      "Finally, use reduce to combine all these elements.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = (b-a)/n * reduce(+,map(fetch,{ (@spawnat p sum(normal_pdf(localpart(x)))) for p in procs(x) }))\n",
      "end\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0)\n",
      "@time  int_normal_pdf(-1.0,1.0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "078581017 seconds (24842000 bytes allocated)\n",
        "elapsed time: 0.074408364 seconds (24545924 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "0.6826896908849678"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, @parallel is better suited for small loops that execute quickly.\n",
      "Map and pmap are more useful for distributing more time consuming functions.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Q2.  In this exercise, you'll parallelize a more time consuming simulation task.  We'll consider a population of stars, each of which has a  probability $\\eta$ of having one planet.  Then we'll assume a that the planets' orbital periods are drawn from a truncated inverse gamma distribution.  An inverse gamma distribution takes two model parameters, one shape parameter that is like a power-law index for large orbital periods and one scale factor that determines below what period planets will become much less common.  We'll truncate the period distribution, so that no planets orbit inside a star or have a period greater than 4/3 of a year (based on Kepler's mission lifetime).  Each planet has a probability of transiting it's star approximated by $R_*/a$, where $R_*$ is the radius of the star and a is the semi-major axis of the orbit (related to orbital period via Kepler's third law).  (For simplicity, we'll make many assumptions like all stars will be one solar mass and one solar radius, no planet will be too small to be detected above the noise, each star can have only zero or one planets, planets will be on circular orbits, etc. )   We will generate one set of \"observations\" using a particular set of parameter values.  Then we will explore the three-dimensional parameter space ($\\eta$, shape, scale), pretending that we don't know the true values.   For each set of model parameters that we consider, we'll generate one (or more) simulated data sets and comapre those to the \"observations\" via several summary statistics (e.g., number of transiting planets, mean period of transiting planets, standard deviation of transiting planets, etc.) and record a \"distance\" between the summary statistics of the observations and the summary statistics for the simulated data.  You can then plot various projections of this 3-d function to gain intuition for what combinations of $\\eta$, shape and scale are plaussible matches to the data.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2a.  First, read through and load the two files that contain a starter program.\n",
      "Then, perform a set of simulations using parameters similar to those below.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere include(\"HW6_Q2_planet_populations_once.jl\")  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: could not import Base.foldl into NumericExtensions\n",
        "Warning: could not import Base.foldr into NumericExtensions\n",
        "Warning: could not import Base.sum! into NumericExtensions\n",
        "Warning: could not import Base.maximum! into NumericExtensions\n",
        "Warning: could not import Base.minimum! into NumericExtensions\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: could not import Base.foldl into NumericExtensions\n",
        "Warning: could not import Base.foldr into NumericExtensions\n",
        "Warning: could not import Base.foldl into NumericExtensions\n",
        "Warning: could not import Base.sum! into NumericExtensions\n",
        "Warning: could not import Base.foldr into NumericExtensions\n",
        "Warning: could not import Base.maximum! into NumericExtensions\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: could not import Base.minimum! into NumericExtensions\n",
        "Warning: could not import Base.sum! into NumericExtensions\n",
        "Warning: could not import Base.maximum! into NumericExtensions\n",
        "Warning: could not import Base.minimum! into NumericExtensions\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading help data...\tFrom worker 2:\tLoading help data...\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: Possible conflict in library symbol dtrtri_\n",
        "Warning: Possible conflict in library symbol dgetri_\n",
        "Warning: Possible conflict in library symbol dgetrf_\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: Possible conflict in library symbol dtrtri_\n",
        "Warning: Possible conflict in library symbol dgetri_\n",
        "Warning: Possible conflict in library symbol dgetrf_\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "exception on 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        ": ERROR: error in method definition: function Base.bytestring must be explicitly imported to be extended\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " in include at boot.jl:238\n",
        " in include_from_node1 at loading.jl:114\n",
        " in include at boot.jl:238\n",
        " in include_from_node1 at loading.jl:114\n",
        " in reload_path at loading.jl:140\n",
        " in _require at loading.jl:58\n",
        " in require at loading.jl:43\n",
        " in include at boot.jl:238\n",
        " in include_from_node1 at loading.jl:114\n",
        " in eval at /Users/sabae/tmp/julia-packaging/osx/julia-master/base/sysimg.jl:4\n",
        " in anonymous at multi.jl:1326\n",
        " in run_work_thunk at multi.jl:575\n",
        " in run_work_thunk at multi.jl:584\n",
        " in anonymous at task.jl:88\n",
        "at /Users/nicholassenno/.julia/PyPlot/src/latex.jl:24\n",
        "at /Users/nicholassenno/.julia/PyPlot/src/PyPlot.jl:390\n",
        "at /Users/nicholassenno/Desktop/HPC/HW6/HW6_Q2_planet_populations_once.jl:3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tFrom worker 3:\tLoading help data...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: Possible conflict in library symbol dtrtri_\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: Possible conflict in library symbol dgetri_\n",
        "Warning: Possible conflict in library symbol dgetrf_\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere include(\"HW6_Q2_planet_populations.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_eta = 0.0\n",
      "max_eta = 1.0\n",
      "min_shape = 0.0001\n",
      "max_shape = 1.0\n",
      "min_log_scale = log10(0.3)\n",
      "max_log_scale = log10(3.0)  \n",
      "num_eta = 4\n",
      "num_shape = 4\n",
      "num_scale = 4\n",
      "num_evals = 1\n",
      "etas = linspace(min_eta,max_eta,num_eta)\n",
      "scales = 10.0.^linspace(min_log_scale,max_log_scale,num_scale)\n",
      "shapes = linspace(min_shape,max_shape,num_shape)\n",
      "num_stars = 16000\n",
      "eta = 0.2\n",
      "shape = 0.1\n",
      "scale = 1.0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42)\n",
      "@time result = eval_model_on_grid_loops(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "days_in_year not defined\nat In[5]:44",
       "output_type": "pyerr",
       "traceback": [
        "days_in_year not defined\nat In[5]:44",
        " in eval_model_on_grid_loops at /Users/nicholassenno/Desktop/HPC/HW6/HW6_Q2_planet_populations.jl:135"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that for speed's sake, I've limited the number of function evaluations to only 4 in each of the three model parameters.  \n",
      "Additionally, I've reduced the number of stars to only 16000.  Kepler observed ~160,000 stars at a time.  \n",
      "\n",
      "You might like to plot the results, using a command such as "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using PyPlot\n",
      "imshow(log10(scales),shapes,[minimum(result[:,j,k]) for j in 1:num_scale, k in 1:num_shape])\n",
      "plot(log10([scale]),[shape],\"ro\")  # Put dot where true values of parameters are\n",
      "xlabel(L\"$\\log_{10}(\\mathrm{scale})$\");  ylabel(\"shape\");\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading help data...\tFrom worker 2:\tLoading help data...\n",
        "\tFrom worker 3:\tLoading help data...\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: Possible conflict in library symbol dtrtri_\n",
        "Warning: Possible conflict in library symbol dtrtri_\n",
        "Warning: Possible conflict in library symbol dgetri_\n",
        "Warning: Possible conflict in library symbol dgetri_\n",
        "Warning: Possible conflict in library symbol dgetrf_\n",
        "Warning: Possible conflict in library symbol dgetrf_\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: Possible conflict in library symbol dtrtri_\n",
        "Warning: Possible conflict in library symbol dgetri_\n",
        "Warning: Possible conflict in library symbol dgetrf_\n"
       ]
      },
      {
       "ename": "LoadError",
       "evalue": "error in method definition: function Base.bytestring must be explicitly imported to be extended\nat /Users/nicholassenno/.julia/PyPlot/src/latex.jl:24\nat /Users/nicholassenno/.julia/PyPlot/src/PyPlot.jl:390\nat In[19]:1",
       "output_type": "pyerr",
       "traceback": [
        "error in method definition: function Base.bytestring must be explicitly imported to be extended\nat /Users/nicholassenno/.julia/PyPlot/src/latex.jl:24\nat /Users/nicholassenno/.julia/PyPlot/src/PyPlot.jl:390\nat In[19]:1",
        " in include at boot.jl:238",
        " in include_from_node1 at loading.jl:114",
        " in include at boot.jl:238",
        " in include_from_node1 at loading.jl:114",
        " in reload_path at loading.jl:140",
        " in _require at loading.jl:58",
        " in require at loading.jl:43"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2b.  Parallelize at least one of the for loops to speed up the calculations in eval_model_on_grid_loops.  Test that your code gives similar results for at least a few sets of parameter values. (To save time, you don't need to test every point on the grid).  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2c.  Compare the performance of your parallel code to the serial code while varrying the number of processors (e.g., 1, 2, 4, 8).\n",
      "For your benchmarking, make sure you use a computer that has at least 8 cores.  How does the wall clock time scale with the number of processors?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2d.  Modify part of the code, so as to replace the for loops in eval_model_on_grid_map with a call to the map function.  \n",
      "First, test this using a single processor.  Once that works, switch map to pmap and retest."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2e.  Compare the performance of your parallel code using map to the parallel code using @parallel.  \n",
      "Again, varry the number of processors (e.g., 1, 2, 4, 8) and make sure you use a computer that has at least 8 cores.  \n",
      "How does the wall clock time scale with the number of processors?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2f.  Modify the code from 2e so as to make use of DistributedArrays.  Retest."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2g. Compare the performance of your parallel code using DistributedArrays to that of your code using standard arrays.  \n",
      "Explain why the performance is does not improve more signiifcantly.  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}