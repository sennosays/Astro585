{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Astro 585 Sprint 2014<br>\n",
      "Homework 6: Parallel Computing: Multi-core Workstations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q1a. The function nprocs() gives the number of processes that Julia has access to. Normally there is one \"boss\" process with the other \"workers\" doing the deligated work. If nprocs > 1 then nworkers = nprocs -1 else the nprocs = nworkers = 1.\n",
      "\n",
      "1b. The error message that normal_pdf is not defined is being generated because it was defined only for the boss process. In order for the workers to have access to the function definition it needs to be called using @everywhere or to be loaded from a .jl file using reload(\"filename\") etc. \n",
      "\n",
      "1c. I believe we are still getting an error because a race condition is being set up. Every worker process is trying to access and add to the \"integral\" variable. Therefore, I'm not sure how this is delt with in Julia but as it is being checked in the test_int_normal_pdf function, \"integral\" may still be being accessed by other worker processes. In order to get around this we can call the reduce function which regulates which process accesses a variable in a way that produces the right answer.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q2. I've written a parallel version of the code provided in HW6_Q2_planet_populations.jl. To run them, run the code found in parallel_run_q2.jl while making sure you are on a machine with the appropriate number of cores. I've changed this version to run using up to 3 cores. The part that will allow it to run using up to 9 cores is commented out (line 31 of parallel_run_q2.jl). Also note that the call to add the package Distributions has be commented out. This is required to run on one of the rcc clusters. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include(\"parallel_run_q2.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: redefining constant days_in_year\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "running on 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " core(s)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 27"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".606058927 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: redefining constant days_in_year\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: could not import Base.foldl into NumericExtensions\n",
        "Warning: could not import Base.foldr into NumericExtensions\n",
        "Warning: could not import Base.sum! into NumericExtensions\n",
        "Warning: could not import Base.maximum! into NumericExtensions\n",
        "Warning: could not import Base.minimum! into NumericExtensions\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Warning: could not import Base.foldl into NumericExtensions\n",
        "Warning: could not import Base.foldr into NumericExtensions\n",
        "Warning: could not import Base.sum! into NumericExtensions\n",
        "Warning: could not import Base.maximum! into NumericExtensions\n",
        "Warning: could not import Base.minimum! into NumericExtensions\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "running on 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " core(s)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".929571262 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Max error was found to be 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13918876306350692\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The major change is found in parallel_q2.jl line 143 where the inner most for loop was changed to a pmap function. Every other additon includeing the front end code in parallel_run_q2.jl are simply used to prepare the calculation for parallelization. All the rest of the calculation is performed serially. The way the code runs known allows for the most uniformity, because each worker has roughly the same amount of work to do assuming the limit of large amounts of planets and evaluations. I've thought about making additional parallelization where each worker has its own additional worker processes which parallelize further nested for loops. For example, worker number 1 could potentially split its work amount a one or two additional processes. This may be more useful for distributed arrays where some processers are on the same node and can easily communicate while others are many switches away. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The results from paralell_run_q2.jl are written to the text file time_results.txt and include the number of evaluations for each set of parameters, the maximum error found between the seraial solution and any parallelized solution, and the time taken to complete the calculation as a function of the number of processors used. Notice that because some of the calculation uses random numbers and the way the problem is parallelized affects the order in which those parallel numbers are drawn, using a different number of processors will change the result. In the limit of a large number of evaluations $N$ we expect this error to go as $\\sim 1/\\sqrt{N}$. I've written a script to view all of the results \"I DON'T KNOW WHAT THIS FILE NAME IS YET .JL\" which can be used with this copy parallel_run_q2.jl or with the results obtained from the lionxj system by changing the file that is read in. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}